# ASR(Automatic Speech Recognition on Multiple Ghanaian Languages)
Develop an automatic speech recognition (ASR) model using Speech Dataset collected by UG

## Dataset pre-processing
The dataset pre-porcessing was one of the time consuming yet interesting stage for me. It started first with getting to understand download the dataset onto my personal computer. With the dataset being large, I was only able to achieve this by purchasing a month free trial subscription on Dropbox, the leverage the dropbox storage to reduce burden on my personal computer. I spent days getting to understand the dataset, from listening to audios and also going through the selected transcribed audio excel sheet to understand the dataset. After have a fair understanding of the dataset, I decided to use only the selected transcripts audio files, firstly because not doing so wasn’t going to be possible because of my machine memory 
Setback, and secondary due to the fact that it had a transcription to it audio. So I had it in mind to employ supervised learning for its training. 

## Creation of Dataframe
I began first by reading the data from all five languages excel sheet existing in the selected transcribed audio directory into a dataframe object. After which I then combined all five data frames as one for a single processing of all datasets I will be using. The combination of all the dataset after cleanup was about 93,166, which was very large. So I thought to obtain a sample 1350  grouped by each of the locale, which amounted to a total of 1350 by 5 = 6750. Albeit it being a large dataset, it was not feasible or train worthy as  most of its class had less than 2 occurrence. So I decided to go with data augmentation, I initially started big, changing audio_file pitch by a list of steps but then I had to reduce it because of the limited resource of my machine and also because it would have made training very hard for me. I used to main augmentation process, i.e. sound and pitch change, each by a single value. The sound augmented was only employed after the pitch change augmentation resulted in the corruption of about 5% of the files. After successfully augmenting, I was left with a data size of 13,500 which was perfect and trainable. I began to now move towards the development of the model.

## Model development
At this point, I was ready to start converting my audio_file to melspectrogram and the transcription to it token format(pre-process it into it individual words through word slicing). I began first by splitting the dataset into both training and testing, 75% training and 25% testing. Then right after, I plugged the result of the split corresponding to the training data into the function responsible for converting the audio_file into melspectrogram and the transcriptions into token. It was at this point I started realizing the problem with my sample size or sampling because somehow converting the result of the spectrogram into a numpy array kept failing, pointing to “inhomogeneous nature of the shape of the result array.” After several attempt to fix this problem and still not being able to move past it, I decided to include a type to the resulting array, i.e. type object. It worked out perfectly until it was time to plug the training_data into the CNN model. The CNN model architecture required an input shape and number of classes. The input shape the CNN model required was 3 dimensional(batch size, heights, widths, channels). The batch size should have represented the number of images in the batch, the height, the height of each image, width, the width of each image and the channels, the number of channels in each image, for RGB images, it would be three. I tried to reshape the extracted feature numpy array but it kept raising error, I am sure it has something to do with the irregularity or un-normalized nature or sizing of the occurring audio_files existing in the sample data prior to augmentation and post augmentation. Moving on, the number of classes also happens to be very huge(more than 6000), reducing the count or representation of its unique class. Unfortunately due to this setback I was unable to proceed to Training, Evaluation and Testing, even though I prepared for them in terms of code. 
